@echo off
:: Ollama ìƒíƒœ í™•ì¸ ë° í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

setlocal enabledelayedexpansion
chcp 65001 >nul
cls

echo.
echo ðŸ” Ollama ìƒíƒœ í™•ì¸ ë° í…ŒìŠ¤íŠ¸
echo ===============================
echo.

:: 1. Ollama ì„¤ì¹˜ í™•ì¸
echo ðŸ“‹ 1. Ollama ì„¤ì¹˜ í™•ì¸
echo =====================
ollama --version
if %errorlevel% neq 0 (
    echo âŒ Ollamaê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.
    echo    install-ollama-simple.batì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.
    goto :end
)
echo âœ… Ollama ì„¤ì¹˜ í™•ì¸ë¨
echo.

:: 2. ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
echo ðŸ”„ 2. ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸  
echo ======================
curl -s -m 5 http://localhost:11434 >nul 2>&1
if %errorlevel% neq 0 (
    echo âŒ Ollama ì„œë¹„ìŠ¤ê°€ ì‹¤í–‰ë˜ì§€ ì•Šê³  ìžˆìŠµë‹ˆë‹¤.
    echo.
    set /p START_SERVICE="ì„œë¹„ìŠ¤ë¥¼ ì‹œìž‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (Y/n): "
    if /i "!START_SERVICE!" neq "n" if /i "!START_SERVICE!" neq "N" (
        echo ì„œë¹„ìŠ¤ ì‹œìž‘ ì¤‘...
        start /min "Ollama Service" ollama serve
        
        echo ì„œë¹„ìŠ¤ ì‹œìž‘ ëŒ€ê¸° ì¤‘... (ìµœëŒ€ 15ì´ˆ)
        for /L %%i in (1,1,15) do (
            timeout /t 1 /nobreak >nul 2>&1
            curl -s -m 2 http://localhost:11434 >nul 2>&1
            if !errorlevel! equ 0 (
                echo âœ… ì„œë¹„ìŠ¤ ì‹œìž‘ ì™„ë£Œ! (%%iì´ˆ)
                goto :service_ready
            )
        )
        echo âŒ ì„œë¹„ìŠ¤ ì‹œìž‘ ì‹¤íŒ¨
        goto :end
    ) else (
        echo ì„œë¹„ìŠ¤ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì‹œìž‘í•´ì£¼ì„¸ìš”: ollama serve
        goto :end
    )
) else (
    echo âœ… Ollama ì„œë¹„ìŠ¤ ì‹¤í–‰ ì¤‘
)

:service_ready

:: 3. API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸
echo.
echo ðŸŒ 3. API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸
echo ==========================

echo ê¸°ë³¸ ì—”ë“œí¬ì¸íŠ¸ (/) í…ŒìŠ¤íŠ¸...
curl -s -m 5 http://localhost:11434/ 
echo.

echo /api/tags ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸...
curl -s -m 5 http://localhost:11434/api/tags | python -m json.tool 2>nul
if %errorlevel% neq 0 (
    echo âŒ /api/tags ì—”ë“œí¬ì¸íŠ¸ ì˜¤ë¥˜
    curl -s -m 5 http://localhost:11434/api/tags
) else (
    echo âœ… /api/tags ì—”ë“œí¬ì¸íŠ¸ ì •ìƒ
)
echo.

:: 4. ì„¤ì¹˜ëœ ëª¨ë¸ í™•ì¸
echo ðŸ“š 4. ì„¤ì¹˜ëœ ëª¨ë¸ í™•ì¸
echo ===================
ollama list
if %errorlevel% neq 0 (
    echo âŒ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨
    echo.
) else (
    echo âœ… ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì„±ê³µ
    echo.
)

:: ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ í™•ì¸
echo ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ í™•ì¸ ì¤‘...
ollama list | findstr "llama" >nul 2>&1
if %errorlevel% neq 0 (
    echo âš ï¸ llama ëª¨ë¸ì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.
    echo.
    set /p INSTALL_MODEL="ê¸°ë³¸ ëª¨ë¸ì„ ì„¤ì¹˜í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (1=ê²½ëŸ‰ 3B / 2=ê³ ì„±ëŠ¥ 8B / n=ê±´ë„ˆë›°ê¸°): "
    if "!INSTALL_MODEL!"=="1" (
        echo ðŸ“¥ llama3.2:3b ëª¨ë¸ ì„¤ì¹˜ ì¤‘... (ì•½ 2GB)
        ollama pull llama3.2:3b
    ) else if "!INSTALL_MODEL!"=="2" (
        echo ðŸ“¥ llama3.1:8b ëª¨ë¸ ì„¤ì¹˜ ì¤‘... (ì•½ 4.7GB)
        ollama pull llama3.1:8b
    )
) else (
    echo âœ… llama ëª¨ë¸ì´ ì„¤ì¹˜ë˜ì–´ ìžˆìŠµë‹ˆë‹¤.
)

:: 5. API í˜¸ì¶œ í…ŒìŠ¤íŠ¸
echo.
echo ðŸ§ª 5. API í˜¸ì¶œ í…ŒìŠ¤íŠ¸
echo ==================

:: ì‚¬ìš©í•  ëª¨ë¸ ì„ íƒ
for /f "tokens=1" %%a in ('ollama list ^| findstr "llama" ^| head -1') do set TEST_MODEL=%%a
if "!TEST_MODEL!"=="" (
    echo âŒ í…ŒìŠ¤íŠ¸í•  ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.
    echo    ëª¨ë¸ì„ ë¨¼ì € ì„¤ì¹˜í•´ì£¼ì„¸ìš”: ollama pull llama3.2:3b
    goto :end
)

echo í…ŒìŠ¤íŠ¸ ëª¨ë¸: !TEST_MODEL!
echo.

:: /api/generate í…ŒìŠ¤íŠ¸
echo /api/generate ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸...
curl -s -m 10 -X POST http://localhost:11434/api/generate ^
  -H "Content-Type: application/json" ^
  -d "{\"model\": \"!TEST_MODEL!\", \"prompt\": \"Hello, what is 2+2?\", \"stream\": false}" ^
  | python -m json.tool 2>nul

if %errorlevel% equ 0 (
    echo âœ… /api/generate ì—”ë“œí¬ì¸íŠ¸ ì •ìƒ
) else (
    echo âŒ /api/generate ì—”ë“œí¬ì¸íŠ¸ ì˜¤ë¥˜
    echo ì§ì ‘ ì‘ë‹µ:
    curl -s -m 10 -X POST http://localhost:11434/api/generate ^
      -H "Content-Type: application/json" ^
      -d "{\"model\": \"!TEST_MODEL!\", \"prompt\": \"Hello, what is 2+2?\", \"stream\": false}"
)
echo.

:: /api/chat í…ŒìŠ¤íŠ¸ (ìžˆëŠ” ê²½ìš°)
echo /api/chat ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸...
curl -s -m 10 -X POST http://localhost:11434/api/chat ^
  -H "Content-Type: application/json" ^
  -d "{\"model\": \"!TEST_MODEL!\", \"messages\": [{\"role\": \"user\", \"content\": \"Hello, what is 2+2?\"}], \"stream\": false}" ^
  | python -m json.tool 2>nul

if %errorlevel% equ 0 (
    echo âœ… /api/chat ì—”ë“œí¬ì¸íŠ¸ ì •ìƒ
) else (
    echo âš ï¸ /api/chat ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš© ë¶ˆê°€ (ì´ì „ ë²„ì „ì¼ ìˆ˜ ìžˆìŒ)
    echo   /api/generate ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
)
echo.

:: 6. ì±—ë´‡ ì—°ë™ í…ŒìŠ¤íŠ¸
echo ðŸ¤– 6. ì±—ë´‡ ì—°ë™ í…ŒìŠ¤íŠ¸
echo ====================

if exist .venv\Scripts\activate.bat (
    echo ê°€ìƒí™˜ê²½ í™œì„±í™” ì¤‘...
    call .venv\Scripts\activate.bat
    
    echo Python AI ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ ì¤‘...
    python -c "
import sys
sys.path.append('.')
try:
    from ai_backend.services import AIService
    ai = AIService()
    if ai.ollama_available:
        print('âœ… AI ì„œë¹„ìŠ¤ ì—°ê²° ì„±ê³µ')
        print('ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸:', ai.get_available_models())
    else:
        print('âŒ AI ì„œë¹„ìŠ¤ ì—°ê²° ì‹¤íŒ¨')
except Exception as e:
    print('âŒ AI ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨:', str(e))
"
) else (
    echo âš ï¸ ê°€ìƒí™˜ê²½ì´ ì—†ìŠµë‹ˆë‹¤. install-minimal.batì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.
)

echo.
echo ðŸ“‹ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!
echo ==============
echo.

:: ê²°ê³¼ ìš”ì•½
echo ðŸ”§ ë¬¸ì œ í•´ê²° ë°©ë²•:
echo.
echo 1. ì„œë¹„ìŠ¤ ì‹œìž‘ ì•ˆë¨:
echo    - ìˆ˜ë™ ì‹œìž‘: ollama serve
echo    - ë°±ê·¸ë¼ìš´ë“œ ì‹œìž‘: start /min ollama serve
echo.
echo 2. ëª¨ë¸ ì—†ìŒ:
echo    - ê²½ëŸ‰ ëª¨ë¸: ollama pull llama3.2:3b
echo    - ê³ ì„±ëŠ¥ ëª¨ë¸: ollama pull llama3.1:8b
echo.
echo 3. API ì˜¤ë¥˜:
echo    - í¬íŠ¸ í™•ì¸: netstat -an | findstr 11434
echo    - ë¡œê·¸ í™•ì¸: ollama logs
echo    - ìž¬ì‹œìž‘: taskkill /f /im ollama.exe ^& ollama serve
echo.
echo 4. ì±—ë´‡ ì—°ë™ ì˜¤ë¥˜:
echo    - ì„œë²„ ìž¬ì‹œìž‘: run-daphne.bat
echo    - ë¸Œë¼ìš°ì € ìƒˆë¡œê³ ì¹¨: Ctrl+F5
echo.

:end
echo ì•„ë¬´ í‚¤ë‚˜ ëˆ„ë¥´ë©´ ì¢…ë£Œë©ë‹ˆë‹¤...
pause >nul
