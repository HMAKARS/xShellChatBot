#!/usr/bin/env python3
"""
Ollama AI ì—°ê²° í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
XShell ì±—ë´‡ì˜ AI ê¸°ëŠ¥ ì—°ê²° ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
"""

import os
import sys
import requests
import json
from typing import Dict, Any, List

# Django ì„¤ì • ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'xshell_chatbot.settings')

try:
    import django
    django.setup()
    from ai_backend.services import AIService, OllamaClient
    from django.conf import settings
    DJANGO_AVAILABLE = True
except Exception as e:
    print(f"âš ï¸ Django ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {e}")
    DJANGO_AVAILABLE = False

def test_ollama_connection():
    """Ollama ê¸°ë³¸ ì—°ê²° í…ŒìŠ¤íŠ¸"""
    print("ğŸ” Ollama ì—°ê²° í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    base_url = "http://localhost:11434"
    
    # 1. ê¸°ë³¸ ì—°ê²° í…ŒìŠ¤íŠ¸
    try:
        response = requests.get(f"{base_url}/", timeout=5)
        if response.status_code == 200:
            print("âœ… Ollama ì„œë¹„ìŠ¤ ì—°ê²° ì„±ê³µ")
            print(f"   ì‘ë‹µ: {response.text.strip()}")
        else:
            print(f"âŒ Ollama ì„œë¹„ìŠ¤ ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}")
            return False
    except requests.RequestException as e:
        print(f"âŒ Ollama ì„œë¹„ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
        print("   í•´ê²° ë°©ë²•: ollama serve ëª…ë ¹ì–´ë¡œ ì„œë¹„ìŠ¤ë¥¼ ì‹œì‘í•˜ì„¸ìš”")
        return False
    
    # 2. ëª¨ë¸ ëª©ë¡ í™•ì¸
    try:
        response = requests.get(f"{base_url}/api/tags", timeout=5)
        if response.status_code == 200:
            models = response.json().get('models', [])
            print(f"âœ… ì„¤ì¹˜ëœ ëª¨ë¸ ê°œìˆ˜: {len(models)}")
            for model in models:
                print(f"   - {model['name']} ({model.get('size', 'unknown')})")
            
            if not models:
                print("âš ï¸ ì„¤ì¹˜ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
                print("   í•´ê²° ë°©ë²•: ollama pull llama3.2:3b")
                return False
        else:
            print(f"âŒ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {response.status_code}")
            return False
    except requests.RequestException as e:
        print(f"âŒ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return False
    
    return True

def test_api_endpoints():
    """API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸"""
    print("\nğŸŒ API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    base_url = "http://localhost:11434"
    
    # ì‚¬ìš©í•  í…ŒìŠ¤íŠ¸ ëª¨ë¸ ì°¾ê¸°
    try:
        response = requests.get(f"{base_url}/api/tags", timeout=5)
        models = response.json().get('models', [])
        if not models:
            print("âŒ í…ŒìŠ¤íŠ¸í•  ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        test_model = models[0]['name']
        print(f"ğŸ“‹ í…ŒìŠ¤íŠ¸ ëª¨ë¸: {test_model}")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ëª¨ë¸ ì„ íƒ ì‹¤íŒ¨: {e}")
        return False
    
    # 1. /api/generate í…ŒìŠ¤íŠ¸
    print("\nğŸ§ª /api/generate ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸")
    try:
        payload = {
            "model": test_model,
            "prompt": "Hello, what is 2+2? Answer briefly.",
            "stream": False,
            "options": {
                "temperature": 0.1,
                "num_predict": 50
            }
        }
        
        response = requests.post(
            f"{base_url}/api/generate", 
            json=payload, 
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            print("âœ… /api/generate ì„±ê³µ")
            print(f"   ì‘ë‹µ: {result.get('response', 'ì‘ë‹µ ì—†ìŒ')[:100]}...")
            print(f"   ì†Œìš” ì‹œê°„: {result.get('total_duration', 0) / 1e9:.1f}ì´ˆ")
        else:
            print(f"âŒ /api/generate ì‹¤íŒ¨: {response.status_code}")
            print(f"   ì˜¤ë¥˜: {response.text}")
            return False
            
    except requests.RequestException as e:
        print(f"âŒ /api/generate ì˜¤ë¥˜: {e}")
        return False
    
    # 2. /api/chat í…ŒìŠ¤íŠ¸
    print("\nğŸ’¬ /api/chat ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸")
    try:
        payload = {
            "model": test_model,
            "messages": [
                {"role": "user", "content": "Hello, what is 2+2? Answer briefly."}
            ],
            "stream": False
        }
        
        response = requests.post(
            f"{base_url}/api/chat", 
            json=payload, 
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            print("âœ… /api/chat ì„±ê³µ")
            message = result.get('message', {})
            print(f"   ì‘ë‹µ: {message.get('content', 'ì‘ë‹µ ì—†ìŒ')[:100]}...")
        elif response.status_code == 404:
            print("âš ï¸ /api/chat ì—”ë“œí¬ì¸íŠ¸ ì—†ìŒ (ì´ì „ ë²„ì „ Ollama)")
            print("   /api/generate ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤")
        else:
            print(f"âŒ /api/chat ì‹¤íŒ¨: {response.status_code}")
            print(f"   ì˜¤ë¥˜: {response.text}")
            
    except requests.RequestException as e:
        print(f"âŒ /api/chat ì˜¤ë¥˜: {e}")
    
    return True

def test_django_ai_service():
    """Django AI ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸"""
    if not DJANGO_AVAILABLE:
        print("\nâš ï¸ Django AI ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ ê±´ë„ˆëœ€ (Django ë¡œë“œ ì‹¤íŒ¨)")
        return False
        
    print("\nğŸ¤– Django AI ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    try:
        # AI ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        ai_service = AIService()
        print(f"âœ… AI ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì„±ê³µ")
        print(f"   Ollama ì‚¬ìš© ê°€ëŠ¥: {ai_service.ollama_available}")
        
        if not ai_service.ollama_available:
            print("âŒ Ollama ì„œë¹„ìŠ¤ ì‚¬ìš© ë¶ˆê°€")
            return False
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ í™•ì¸
        models = ai_service.get_available_models()
        print(f"âœ… ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {len(models)}ê°œ")
        for model in models[:3]:  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
            print(f"   - {model['name']}")
        
        # í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ ì²˜ë¦¬
        test_message = "ì•ˆë…•í•˜ì„¸ìš”. ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤."
        session_id = "test_session"
        
        print(f"\nğŸ“ í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€: {test_message}")
        
        result = ai_service.process_message(
            test_message, 
            session_id, 
            'user',
            {'shell_type': 'auto'}
        )
        
        print("âœ… ë©”ì‹œì§€ ì²˜ë¦¬ ì„±ê³µ")
        print(f"   ì‘ë‹µ ê¸¸ì´: {len(result.get('content', ''))} ë¬¸ì")
        print(f"   ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: {result.get('content', '')[:150]}...")
        
        return True
        
    except Exception as e:
        print(f"âŒ Django AI ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_client_classes():
    """í´ë¼ì´ì–¸íŠ¸ í´ë˜ìŠ¤ ì§ì ‘ í…ŒìŠ¤íŠ¸"""
    if not DJANGO_AVAILABLE:
        return False
        
    print("\nğŸ”§ í´ë¼ì´ì–¸íŠ¸ í´ë˜ìŠ¤ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    try:
        # OllamaClient ì§ì ‘ í…ŒìŠ¤íŠ¸
        client = OllamaClient()
        print("âœ… OllamaClient ìƒì„± ì„±ê³µ")
        
        # ì„œë¹„ìŠ¤ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        available = client.is_available()
        print(f"   ì„œë¹„ìŠ¤ ì‚¬ìš© ê°€ëŠ¥: {available}")
        
        if available:
            # ê°„ë‹¨í•œ ìƒì„± í…ŒìŠ¤íŠ¸
            response = client.generate(
                "Hello, respond with just 'Hi'",
                "You are a helpful assistant. Keep responses very short.",
            )
            print("âœ… í…ìŠ¤íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸ ì„±ê³µ")
            print(f"   ì‘ë‹µ: {response.get('response', 'No response')[:50]}...")
            
            # ì±„íŒ… í…ŒìŠ¤íŠ¸ (í´ë°± í¬í•¨)
            messages = [
                {"role": "user", "content": "Hello, respond with just 'Hi'"}
            ]
            chat_response = client.chat(messages)
            print("âœ… ì±„íŒ… í…ŒìŠ¤íŠ¸ ì„±ê³µ")
            
            # ì‘ë‹µ í˜•ì‹ í™•ì¸
            if 'message' in chat_response:
                content = chat_response['message'].get('content', '')
            else:
                content = chat_response.get('response', '')
                
            print(f"   ì±„íŒ… ì‘ë‹µ: {content[:50]}...")
        
        return True
        
    except Exception as e:
        print(f"âŒ í´ë¼ì´ì–¸íŠ¸ í´ë˜ìŠ¤ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

def print_troubleshooting():
    """ë¬¸ì œ í•´ê²° ë°©ë²• ì¶œë ¥"""
    print("\nğŸ”§ ë¬¸ì œ í•´ê²° ë°©ë²•")
    print("=" * 50)
    
    print("\n1. Ollama ì„œë¹„ìŠ¤ê°€ ì‹¤í–‰ë˜ì§€ ì•ŠëŠ” ê²½ìš°:")
    print("   - ëª…ë ¹ì–´: ollama serve")
    print("   - ë°±ê·¸ë¼ìš´ë“œ: start /min ollama serve")
    print("   - ìƒíƒœ í™•ì¸: curl http://localhost:11434")
    
    print("\n2. ëª¨ë¸ì´ ì„¤ì¹˜ë˜ì§€ ì•Šì€ ê²½ìš°:")
    print("   - ê²½ëŸ‰ ëª¨ë¸: ollama pull llama3.2:3b")
    print("   - ê³ ì„±ëŠ¥ ëª¨ë¸: ollama pull llama3.1:8b")
    print("   - ëª¨ë¸ í™•ì¸: ollama list")
    
    print("\n3. API ì˜¤ë¥˜ê°€ ë°œìƒí•˜ëŠ” ê²½ìš°:")
    print("   - í¬íŠ¸ í™•ì¸: netstat -an | findstr 11434")
    print("   - ì¬ì‹œì‘: taskkill /f /im ollama.exe && ollama serve")
    print("   - ë¡œê·¸ í™•ì¸: ollama logs")
    
    print("\n4. Django ì—°ë™ ì˜¤ë¥˜:")
    print("   - ê°€ìƒí™˜ê²½ í™•ì¸: .venv\\Scripts\\activate")
    print("   - íŒ¨í‚¤ì§€ ì„¤ì¹˜: pip install requests")
    print("   - ì„œë²„ ì¬ì‹œì‘: run-daphne.bat")
    
    print("\n5. ì„±ëŠ¥ ê°œì„ :")
    print("   - GPU ì‚¬ìš©: CUDA ì„¤ì¹˜ í™•ì¸")
    print("   - ë©”ëª¨ë¦¬ í™•ì¸: ìµœì†Œ 8GB RAM ê¶Œì¥")
    print("   - ëª¨ë¸ ë³€ê²½: ë” ì‘ì€ ëª¨ë¸ ì‚¬ìš©")

def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸš€ XShell ì±—ë´‡ AI ì—°ê²° í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    print()
    
    results = {
        'ollama_connection': False,
        'api_endpoints': False,
        'django_service': False,
        'client_classes': False
    }
    
    # 1. Ollama ê¸°ë³¸ ì—°ê²° í…ŒìŠ¤íŠ¸
    results['ollama_connection'] = test_ollama_connection()
    
    # 2. API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸
    if results['ollama_connection']:
        results['api_endpoints'] = test_api_endpoints()
    
    # 3. Django AI ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸
    if results['ollama_connection']:
        results['django_service'] = test_django_ai_service()
    
    # 4. í´ë¼ì´ì–¸íŠ¸ í´ë˜ìŠ¤ í…ŒìŠ¤íŠ¸
    if results['ollama_connection']:
        results['client_classes'] = test_client_classes()
    
    # ê²°ê³¼ ìš”ì•½
    print("\nğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("=" * 50)
    
    for test_name, success in results.items():
        status = "âœ… ì„±ê³µ" if success else "âŒ ì‹¤íŒ¨"
        print(f"{test_name}: {status}")
    
    all_passed = all(results.values())
    if all_passed:
        print("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! AI ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        print("   run-daphne.batì„ ì‹¤í–‰í•´ì„œ ì„œë²„ë¥¼ ì‹œì‘í•˜ì„¸ìš”.")
    else:
        print("\nâš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨. ë¬¸ì œ í•´ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        print_troubleshooting()

if __name__ == "__main__":
    main()
